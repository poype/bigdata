# 流式计算概念

## 更及时地获取数据统计结果

我们希望数据统计的反馈时间能够尽量短些，也就是“实时一点”。而这就触到了像MapReduce这种批处理框架的痛点了。

一般来说，我们的MapReduce作业都是定时执行的，比如每天运行一次，生成一个报表，或者频繁一点，每小时运行一次，计算上一个小时的点击率数据。但是，这个获得反馈数据的频率还是太慢了。

每小时运行一次MapReduce作业程序，意味着我们的统计数据，平均要晚上半个小时。而半个小时里，低质量的广告或者搜索结果已经曝光了很多次了。**让用户能够越早的看到数据统计结果越好。**

## 流批一体

在MapReduce的计算模型下，会有哪些输入数据，是在MapReduce的任务开始之前就确定的。

而对于流式计算，输入的数据集是无边界的，随着时间的推移，不断会有新的输入数据加入进来。

我们把大数据处理分为批处理和流式处理，其实并没有找到两种数据处理的核心差异。因为，对于一份预先确定、边界明确的数据，我们也可以使用流式处理。比如，我们可以把一份固定大小的日志放到Kakfa里，重放一遍给一个Storm的Topology来处理，那也是流式处理，但这是处理的有边界的数据。

而对于不断增长的实时数据，我们一样可以不断定时执行MapReduce这样的批处理任务，或者通过Spark Streaming这样看起来是流式处理，其实是微批（Mini-Batch）的处理方式。

事实上，即使是所谓的“流式”数据处理系统，往往也会为了性能考虑，通过**微批**的方式来提升性能。

一旦从这个视角来观察，那么**批和流本身是一回事儿**。

当我们把“批（Batch）”的记录数限制到了每批一条，那么它就是所谓的流了。

进一步地，“有边界（Bounded）”的数据集，也只是“无边界（Unbounded）”数据集的一种特殊情况。

## 时间窗口

我们进行实时数据处理的时候，我们需要统计的常常是“过去一分钟的热搜”，或者“过去一小时的热搜”，这样有一个时间范围的数据。

又比如，我们需要的往往不是“统计所有的广告展示数量”，而往往是“每 5 分钟统计一次广告展示数量”，或者“统计过去 5 分钟的广告展示数量”。

我们常用的时间窗口，也会分成好几种：

- **固定窗口(Fixed Window)：**比如，我们统计“每小时的广告展示数量”，那么我们的数据，就会被划分成 0 点到 1 点、1 点到 2 点，这样一个个固定区间的窗口。
- **滑动窗口(Sliding Window)：**也就是窗口随着时间的变动在“滑动”。比如，我们要统计“过去 2 分钟的广告展示”，那么我们的窗口并不是划分成 12:00~12:02，12:02~12:04 这样一段段。而是 12:00~12:02，然后一分钟之后变成 12:01~12:03，在这个例子里，2 分钟被称之为窗口大小，而窗口每1分钟“滑动”一次，这个1分钟被称之为**滑动周期**。
- **会话窗口(Session Window)：**这个常常用在统计用户的会话上，对于会话的划分，往往是通过我们设置的两次事件之间的一个“超时时间”来定义的。比如，我们有一个客服聊天系统，如果用户和客服之间超过 30 分钟没有互动，我们就认为上一次会话结束了。在这之后无论是用户主动发言，还是客服主动回复，我们都会认为是进入了一个新的会话。

统计一个不考虑任何时间窗口的数据，往往是没有意义的，1分钟内广告展示了 100 万次，和1个月内展示了100万次代表着完全不同的广告投放力度。**我们需要根据特定的时间窗口，来进行数据统计**。

既然引入了时间窗口这个概念，那我们通常需要的不只是**GroupByKey**，而是**GroupByKeyAndWindow**。

## 有向无环图DAG

为了能够采用“分布式“的方式实时处理接收到的数据，流式处理框架会将整个分布式集群抽象成一个有向无环图DAG，图中的每个节点都是一个计算单元。

每个计算单元可以根据事件类型或事件的key接收到对应的消息，并处理接收到的消息。

在处理完接收到的消息后，计算节点可以将自己的处理结果发送给下游的其它计算节点。

计算节点可以选择在处理完一个消息之后，**立刻**将消息的处理结果发送给下游节点；也可以选择在自己节点内部来维护一个**状态**，然后当处理了一定数量的消息之后，又或者过了一个固定的事件间隔之后把消息处理结果一次发送给下游节点。

最后，在整个有向无环图终点的那些计算节点，会把最终的计算结果发布出去。

这个发布的频率，也和其他计算节点发送消息的逻辑类似，可以每收到一个事件就发送，也可以要求接收到一定数量的事件，或者每隔一个特定的时间间隔再发送。

下图是Apache S4(该计算框架已淘汰)流式计算框架的示意图，

![3496e210bd86382cbcee58c20f0b095e](.\img\3496e210bd86382cbcee58c20f0b095e.webp)

这个程序是用来计算**数量排名Top K的单词**。虽然Apache S4框架已经淘汰了，但还是可以用来说明有向无环图这个特性。

## 大数据处理成熟的技术方案

通过Hadoop/Spark进行批数据处理，通过Hive搭建数据仓库，通过Storm进行流式数据处理，然后通过Kafka作为业务系统和大数据系统之间的消息管道，已经是一个完整而成熟的“标准方案”了。

# Storm

Storm的有向无环图叫做**Topology**。

在Storm的Topology中，有两种类型的节点：

1. **Spout：**数据源
2. **Bolt：**执行计算逻辑的地方，

![storm-flow](.\img\storm-flow.png)

Spout和Bolt之间，Bolt和Bolt之间传递的消息叫做**Tuple**。Tuple是Topology中最小粒度的数据传输单元。

Tuple中可以包含多个KV对，不过各个Key只是在定义Tuple的时候出现。在数据传输的时候，我们只需要传输对应的值。

我们可以在Topology里面，去设置不同 Bolt 的并行度，以及设置数据流是如何分组的。

在Storm里面，对应的数据流可以进行这样几种分组（Grouping）：

**随机分组（Shuffle Grouping）：**也就是每一个Bolt输出的结果，会随机分发给下游不同的Bolt，每个 Bolt 都会收到数量接近的Tuple。

**字段分组（Fields Grouping）：**可以选定Tuple中的**某一个字段**，按照字段**key**的值进行分组。比如我们如果还是要进行单词出现频率的 Top K排序，在每一个Tuple中都包含一个key是word的字段，存放具体的单词，还包含一个key是count的字段，存放它出现的频率。那么，我们可以通过word这个字段进行字段分组，这样**相同单词的Tuple就会分发到相同的Bolt里去**了。

**全部分组（All Grouping）：**这个类似于数据广播，也就是Bolt输出的Tuple需要向下游的每一个Bolt都发送一份。

**全局分组（Global Grouping）：**这个类似于 S4 里你看到的终点的 MergePE，所有上游的Bolt都会把Tuple发送到唯一一个下游Bolt 中。这样在下游，就可以有全局信息来做统计判断。

**无分组（None Grouping）：**这个是说开发人员不关心这个数据怎么分组。在实际实现里面，它和随机分组是一样的。

**指向分组（Direct Grouping）：**这个是上游的Bolt可以指定下游由哪一个 Bolt 来接收对应的Tuple。

**本地或随机分组（Local or Shuffle Grouping）：**也就是当下游的Bolt如果有一个或者多个“任务（Tasks）”，和上游的 Bolt 在同一个 worker进程里，那么Tuple只会分发到这些进程里的任务里。如果没有的话，那就还是按照随机分组的方式发送Tuple。这个主要是为了性能考虑，如果可以在同一个台机器的同一个进程内通信，会大大节省整个集群的网络开销。

![image-20231231192531647](.\img\image-20231231192531647.png)

## Storm架构

Storm是典型的Master+Worker架构：

![image-20231229150846543](.\img\image-20231229150846543.png)

**Nimbus进程：**它是Storm集群的 Master 节点。开发人员会直接提交一个Topology给Master。这个Topology，之前只是一个抽象的有向无环图。而在实际应用里，它就好像一个MapReduce的作业一样，是一个编译好的程序和对应的配置。只不过，MapReduce 的任务执行完了就结束了。而作为流式计算，Topology这个任务如果我们不去终止它，它就会永不停歇地运行下去。

**Supervisor进程：**Supervisor在每一个服务器上都会有一个，它本身不负责执行任务，而是负责接收Nimbus分配的任务，然后管理本地的Worker进程，让Worker进程来实际执行任务。

**Worker进程：**一台服务器上会有多个Worker进程。Storm是使用Clojure写的，跑在 JVM 上，所以每一个 Worker 进程就是一个独立的 JVM。Worker 里面还会通过JVM的Executor来维护一个线程池。然后在实际的线程池里，会有很多个Spout/Bolt 的任务。因为Java的Executor的实现里会复用线程，所以Spout和Bolt实际上会使用同一个线程。这也会大大减少整个系统的开销。

Nimbus和Supervisor 之间，并不是直接通信的。因为如果这样的话，显然 Nimbus 会成为一个故障的“单点”。所以 Nimbus 是把对应的任务分配写到Zookeeper里。所以我们的任务分配是持久化的，而且会由 Paxos 协议来保障容错能力。而 Supervisor 也是从 Zookeeper 里面，去读取对应的任务分配。

Nimbus 和 Supervisor 的职责都非常简单，Nimbus只需要进行Topology的解析和任务调度，而 Supervisor 只需要接收任务，并且监控 Worker进程是否存活。它们本身不处理数据，而且也不在内存里面保存数据。即使挂掉了，也只需要简单重启一下进程就好了。

其实，各类分布式系统的设计思路都是类似的，特别是这样 Master+Worker 组合的模型，那就是 Master 负责调度，Worker 负责实际处理问题。而为了解决高可用性，往往我们会引入分布式锁，确保任务分配的数据不依赖Master。

## Storm错误处理

Storm是通过 ZeroMQ 这个消息队列，完成两个不同的Worker之间的通信的。

相比于通过一个 RPC，消息队列有一个很大的优点，那就是高性能。上游节点不需要等待下游节点返回接收成功，就能发送下一条信息。不过，这也带来了一个问题，就是如果在消息发送之后，下游是否成功接收并处理了这条消息，上游是不知道的。可能因为网络超时、也可能因为下游节点的软硬件故障，在分布式系统里，“错误”是在所难免的。

Storm 选择的解决方案，是把从 Spout 发起的第一个 Tuple 作为一棵树的根。下游所有衍生出来发送的 Tuple，都是这棵树的一部分。任何一个 Tuple 处理失败或者超时了，那么就从 Spout 重新发送消息。

而要做到这一点，Storm 需要在系统里引入一个特殊的 Bolt，叫做 AckerBolt。Spout 发送出去的消息，同时会通知给到 AckerBolt。而 Bolt 一旦处理完根 Tuple 相关的消息，也会通知给到 Acker。

Bolt 会告诉 AckerBolt 两个信息，一个是我已经处理完了某一个 Tuple，另一个是基于这个Tuple 衍生出来的发往下游的那些 Tuple 我也已经发送出去了。这样，Acker 就有了一开始 Spout 发出的 Tuple 的整棵树的完整信息。等到最后一层的 Bolt 处理完对应的 Tuple，然后发送了对应的通知给到 AckerBolt，并且告诉它后面没有新产生的 Tuple 了，那么 AckerBolt 就知道，整棵 Tuple 树已经处理完成了。

![image-20231231193404003](.\img\image-20231231193404003.png)

这个机制只能保障，Spout 发出来的 Tuple 至少被处理一次，也就是 At Least Once，但是它避免不了 Tuple 可能被重复处理。

## Storm框架的缺点

1. **Storm框架本身只能保证At Least Once，不能确保Exactly Once。**
   对于Storm，只要其中有一条消息在下游还没有处理完的时候，KafkaSpout所在的服务器挂掉了，对应的偏移量没有更新。那么在容错机制下，重新启动在另一台服务器上的 KafkaSpout，会重新再发送一遍这一批数据。
   Storm会等到完全确定一小批消息被topology中的所有节点完整的处理完之后，kafkaspout才会更新kafka中的offset。
   ![image-20231229222741237](.\img\image-20231229222741237.png)
   所以使用Storm框架，如果还要必须保证Exactly Once，那只能自己实现幂等去重。
2. **Bolt中的计算状态没有被持久化。**
   当一个Bolt挂掉的时候，维护在其Bolt内部的计算状态就丢失了。这不仅仅使得系统不支持容错，不够高可用。而且还使得整个系统不具备可扩展性。
   所以Bolt会被拆分和迁移，并且在迁移的过程中，我们需要能够保留状态信息，这意味着我们的状态需要能够持久化下来。
   我们需要能够把Bolt的计算状态保存到一个稳定的外部存储中去。当我们的Bolt节点挂掉，在其它服务器上重新启动之后，需要把这些状态信息重新读取回来。这个能力也使得我们去调度计算变得更容易了，我们可以动态地在线上增加系统的并行度。
3. **使用的是消息被处理的时间，不是消息真正发生的时间。**
   这在很多场景下我们是无法容忍的。一种情况是和业务需求相关，计算结果的时间与事件发生的真实时间有偏差。另一种情况，则是当我们重放日志的时候，可能是在事件发生之后很久，这样时间的偏差就更大。

所以新的流式数据处理框架有下面三个目标：

**第一个目标：**exactly once

**第二个目标：**通过把各个计算节点的中间状态持久化，使得系统在容错情况下，仍然能够做到“正好一次”的数据处理，并且能够在线上动态扩容、调度计算。

**第三个目标：**处理消息的时间窗口

在实际的流式数据处理中，从事件发生，到消息被处理会有一定的延时，而且消息之间并不一定会按照它们发生的时间顺序被处理。

要想使用Event真正发生的时间处理数据，要做到如下两点：

1. 把Event真正的发生时间携带上。
2. 要能判断在什么时刻，属于一个时间窗口的全部数据都已经被接收了。这意味着节点可以开始对那个时间窗口内的所有数据进行计算并向下游输出计算结果。

我们需要一个新的流式系统，能够达成三点目标：

**第一点**，是“正好一次”的数据处理机制，要做到这一点，我们需要在流式数据系统里，内置一个数据去重的机制。

**第二点，**是把计算节点需要使用的“状态”信息持久化下来。这样，我们才能够做到真正的容错，而不是在系统出错的时候丢失一部分信息。而且，这个机制也有助于我们在线扩容。

**第三点，**够准确地根据事件发生时间生成报表，而不是简单地使用进行处理的服务器的本地时间。并且，还需要能够考虑到分布式集群中，数据的传输可能会有延时的情况出现。我们需要把流式数据处理的时间窗口，以及触发机制内置到流式处理系统里面去。这样，我们就可以让我们的业务代码，专注于实现业务逻辑，而不是需要自己在应用代码里，搞一套时间窗口的维护和触发机制。

# 低水位(Low Watermark)

在MillWheel 的系统里，每一条消息都可以被解析成（Key, Value, TimeStamp）这样一个三元组的组合。这里面的 TimeStamp，其实就是我们需要的事件发生的时间。

要有一个机制，能够让每个Computation(计算节点)都知道，某个时间点之前的日志应该都已经处理完了。

MillWheel引入的低水位是这样一个概念，在某一个Computation A里，我们可以拿到所有还没有处理完的消息里面，最早的那个时间戳。这个最早的时间戳，就是一个“低水位”。这个“低水位”，其实就是告诉了我们，当前这个Computation的计算节点里，哪个最早的时间点还有消息没有处理完。

获取到了当前 Computation 的低水位，我们就能决策是否应该进一步等待更多的消息，以获得准确的统计数据，还是现有的数据已经是完整的，我们可以把结果输出出去了。

MillWheel是这么实现：每一个Computation节点，都会统计自己处理的所有日志的“低水位”信息，然后上报给一个 Injector 模块，而这个Injector模块，会收集所有的Computation节点的低水位信息。接着，它会通过Injector，把相应的水位信息下发给各个Computation节点，由各个 Computation节点自己，来计算自己最终的低水位是什么。

每一个计算节点，都会根据本地以及它依赖的上游Computation计算出自己当前的Low Watermark：

![image-20231230113450497](.\img\image-20231230113450497.png)

有了这个水位信息，我们统计某一个时间段的统计数据，就可以做到基本准确了。

Google 给出的经验数据，是只有0.001%(十万分之一)的日志，在考虑了水位信息之后仍然会因为来得太晚而被丢掉。但实际上，由于所有数据都是持久化的，即使这些消息来得太晚，我们仍然可以纠正之前的统计数据。

## 采用低水位信息的缺点

这个基于水位的方法在实践中，会有如下两点问题：

- 第一个，在实际的水位标记之后，仍然无法完全避免会有新的日志到达。比如，水位信息告诉我们最早的还没有处理的日志是12:01 的，那么我们自然可以把12:00的统计数据发出去。但是，很有可能一分钟后，我们收到了一条12:00的日志数据，这是因为之前某一个节点挂掉了，恢复传输花了一些时间。那么在这种情况下，我们已经往下游发送的数据就是不准确的。而这种情况，对于数据准确性要求高的需求来说，比如广告计费，就让人难以接受。
- 第二个，我们的水位标记，因为需要考虑上游所有节点。只要有一条日志来晚了，我们的水位就会特别“低”，导致我们迟迟无法输出计算结果。比如，虽然已经到了12:00了，但是我们就是偶尔会出现一条11:05的日志，那么我们的水位一直会卡在11:05，计算结果就会迟迟不能向下游发送。

## 解决低水位信息的缺点

Dataflow 里，是怎么解决这个问题的呢？就是我们可以尽快给出一个计算结果，但是在后续根据获得的新的数据，**不断去修正这个计算结果**。而这个思路，在 Dataflow 里，就体现为触发器（Trigger）机制。

在 Dataflow 里，除了内置的基于水位信息的完成度触发器，它还能够支持基于处理时间、记录数等多个参数**组合触发**。而且用户可以实现自定义触发器，完全根据自己的需要来实现触发器逻辑。

- 首先是抛弃（Discarding）策略，也就是触发之后，对应窗口内的数据就被抛弃掉了。这意味着后续如果有窗口内的数据到达，也没法和上一次触发时候的结果进行合并计算。但这样做的好处是，每个计算节点的存储空间占用不会太大。一旦触发向下游输出计算结果了，现有的数据我们也就不需要了。比如，一个监控系统，根据本地时间去统计错误日志的数量并告警，使用这种策略就会比较合适。
- 然后是累积（Accumulating）策略，也就是触发之后，对应窗口内的数据，仍然会持久化作为状态保存下来。当有新的日志过来，我们仍然会计算新的计算结果，并且我们可以再次触发，向下游发送新的计算结果，而下游也会用新的计算结果来覆盖掉老的计算结果。
  这个是一个典型的 Lambda 架构的思路。我们一般的统计数据，都可以采用这个策略。一方面，我们会尽快根据水位信息，把计算结果发送给下游，使得计算结果的延时尽可能得小。另一方面，在有新的数据过来的时候，我们也会重新修正计算结果。

# 幂等和状态持久化

每一个 Computation + Key 的组合，在接收到一条消息的处理过程是这样的：

- 第一步，自然是**消息去重**，这个可以通过分段的BloomFilter来解决。
  为了解决数据去重，MillWheel通过为每一个收发的记录都创建了一个唯一的 ID，然后通过Bloomfilter对处理过的消息进行去重，确保所有的操作都是幂等的。
- 第二步，就是处理用户实现的业务逻辑代码，在这些代码中，所有产生的更新都被视作是对于“状态”的变更。
- 第三步，这些**状态的变更，都会被一次性提交给后端的存储层**，也就是 Bigtable 或者 Spanner 里。
- 第四步，因为这些更新都已经持久化了，所以系统会发送 Acked 消息给上游发送消息的 Computation。这里的 Acked 机制和 Storm 的 Acked 机制是类似的，能够确保消息不会丢失，没有 Acked 的消息可以重发，并且会在第一步被去重做到“正好一次的数据处理”。不同的地方在于，**因为处理完的消息会被持久化，所以不需要等消息在整个有向无环图里都处理完，才在起点清理掉消息。每一层可以单独回收掉下游的第一层已经处理完的消息**。
- 最后，则是我们向下游发送的消息会被发送出去。

# 时间窗口操作

## AssignWindows

每一个原始的事件，在我们的业务处理函数之前，其实都是(key, value, event_time)这样一个三元组。而AssignWindows要做的，就是把这个三元组，根据我们的处理逻辑，变成(key, value, event_time, window)这样的四元组。

一个事件不只可以分配给一个时间窗口，而是可以分配给多个时间窗口。比如，我们有一个广告在 12:01 展示给了用户，但是我们统计的是“过去 2 分钟的广告展示”，那么这个事件，就会被分配给[12:00, 12:02) 和[12:01, 12:03) 两个时间窗口，我们原先一条的事件就可以变成多条记录。

下图展示了在分配窗口的时候，可能会生成多条记录：

![image-20231230152659490](.\img\image-20231230152659490.png)

## MergeWindows

通过AssignWindows+MergeWindows的组合，来进行相应的数据统计。以客服 30 分钟没有互动就算作超时的例子来看看。

比如同一个用户下，有三个事件，发生的时间分别是 13:02、13:14、13:57。那么分配窗口的时候，三个窗口会是 [13:02,13:32)，[13:14,13:44) 以及 [13:57,14:27)。前两个时间窗口是有重叠部分的，但是第三个时间窗口并没有重叠，对应的窗口会合并成 [13:02,13:44) 以及 [13:57,14:27) 这样两个时间窗口。

窗口的分配和合并功能，就使得Dataflow可以处理乱序数据。相同的数据以不同的顺序到达我们的计算节点，计算的结果仍然是相同的。并且在这个过程里，我们可以把上一次计算完的结果作为状态持久化下来，**然后每一个新进入的事件，都按照 AssignWindows 和 MergeWindows 的方式不断对数据进行化简**。

![image-20231230153348316](.\img\image-20231230153348316.png)

 
